{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "import operator\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import psycopg2 as pg\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import reciprocal_rank\n",
    "\n",
    "%run '../lib/cookbook/recsys.py'\n",
    "%run '../lib/cookbook/generic_preprocessing.py'\n",
    "%run '../lib/utility.py'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML ## Setting display options for Ipython Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing No Free Games vs All Games models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All Games\n",
    "user_top_games_all = pkl.load(open('../data/preprocessed_data/all_games/user_top_games.pkl', 'rb'))\n",
    "user_top_games_filtered_hours_all = pkl.load(open('../data/preprocessed_data/all_games/user_top_games_filtered_hours.pkl', 'rb'))\n",
    "user_top_games_filtered_hours_0_all = pkl.load(open('../data/preprocessed_data/all_games/user_top_games_filtered_hours_0.pkl','rb'))\n",
    "user_top_games_filtered_percentile_all = pkl.load(open('../data/preprocessed_data/all_games/user_top_games_filtered_percentile.pkl', 'rb'))\n",
    "games_all = pkl.load(open('../data/preprocessed_data/all_games/games.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No Free Games\n",
    "user_top_games = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games.pkl','rb'))\n",
    "user_top_games_filtered_hours = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games_filtered_hours.pkl','rb'))\n",
    "user_top_games_filtered_hours_0 = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games_filtered_hours_0.pkl','rb'))\n",
    "user_top_games_filtered_percentile = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games_filtered_percentile.pkl','rb'))\n",
    "games = pkl.load(open('../data/preprocessed_data/no_free_games/games.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_ag = []\n",
    "for i in range(30):\n",
    "    # train test split\n",
    "    train_val, test = train_test_split(user_top_games_all, test_size=0.2)\n",
    "    interactions_train_all_ag = create_interaction_matrix(df = train_val,\n",
    "                                                     user_col = 'user',\n",
    "                                                     item_col = 'item',\n",
    "                                                     rating_col = 'rating',\n",
    "                                                     threshold = '1')\n",
    "    interactions_test_ag = create_interaction_matrix(df = test,\n",
    "                                             user_col = 'user',\n",
    "                                             item_col = 'item',\n",
    "                                             rating_col = 'rating',\n",
    "                                             threshold = '1')\n",
    "    sparse_train_all_ag = sparse.csr_matrix(interactions_train_all_ag.values)\n",
    "    sparse_test_ag = sparse.csr_matrix(interactions_test_ag.values)\n",
    "    # query best parameters\n",
    "    sqlalchemy_conn = create_sqlalchemy_connection('sqlalchemy_conn_str.txt')\n",
    "    best_parameters = query_best_parameters('sqlalchemy_conn_str.txt')\n",
    "    # train and record auc\n",
    "    model = LightFM(**best_parameters)\n",
    "    model.fit(sparse_train_all_ag,\n",
    "            epochs=15,\n",
    "            num_threads=30)\n",
    "    auc = auc_score(model, sparse_test_ag, sparse_train_all_ag, num_threads=30).mean()\n",
    "    auc_ag.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9089915"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc_ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free Games Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_nf = []\n",
    "for i in range(30):\n",
    "    train_val, test = train_test_split(user_top_games, test_size=0.2)\n",
    "    interactions_train_all_nf = create_interaction_matrix(df = train_val,\n",
    "                                                     user_col = 'user',\n",
    "                                                     item_col = 'item',\n",
    "                                                     rating_col = 'rating',\n",
    "                                                     threshold = '1')\n",
    "    interactions_test_nf = create_interaction_matrix(df = test,\n",
    "                                             user_col = 'user',\n",
    "                                             item_col = 'item',\n",
    "                                             rating_col = 'rating',\n",
    "                                             threshold = '1')\n",
    "    ## create sparse matrices from interactions\n",
    "    sparse_train_all_nf = sparse.csr_matrix(interactions_train_all_nf.values)\n",
    "    sparse_test_nf = sparse.csr_matrix(interactions_test_nf.values)\n",
    "    # train and record auc\n",
    "    model = LightFM(**best_parameters)\n",
    "    model.fit(sparse_train_all_nf,\n",
    "            epochs=15,\n",
    "            num_threads=30)\n",
    "    auc = auc_score(model, sparse_test_nf, sparse_train_all_nf, num_threads=30).mean()\n",
    "    auc_nf.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(auc_nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Model 1, 2, 3, and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No Free Games\n",
    "user_top_games = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games.pkl','rb'))\n",
    "user_top_games_filtered_hours = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games_filtered_hours.pkl','rb'))\n",
    "user_top_games_filtered_hours_0 = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games_filtered_hours_0.pkl','rb'))\n",
    "user_top_games_filtered_percentile = pkl.load(open('../data/preprocessed_data/no_free_games/user_top_games_filtered_percentile.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlalchemy_conn = create_sqlalchemy_connection('sqlalchemy_conn_str.txt')\n",
    "best_parameters = query_best_parameters('sqlalchemy_conn_str.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_1, test_1 = train_test_split(user_top_games, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_all_1 = create_interaction_matrix(df = train_val_1,\n",
    "                                                 user_col = 'user',\n",
    "                                                 item_col = 'item',\n",
    "                                                 rating_col = 'rating',\n",
    "                                                 threshold = '1')\n",
    "sparse_train_1 = sparse.csr_matrix(interactions_train_all_1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_test_1 = create_interaction_matrix(df = test_1,\n",
    "                                         user_col = 'user',\n",
    "                                         item_col = 'item',\n",
    "                                         rating_col = 'rating',\n",
    "                                         threshold = '1')\n",
    "sparse_test_1 = sparse.csr_matrix(interactions_test_1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f7dcf79b6d8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = LightFM(**best_parameters)\n",
    "model_1.fit(sparse_train_1,\n",
    "            epochs=15,\n",
    "            num_threads=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_top_games_filtered_hours_0 = user_top_games.merge(user_top_games_filtered_hours_0, how='left', on=['user','item'])\n",
    "user_top_games_filtered_hours_0.loc[user_top_games_filtered_hours_0['rating_y'].isnull(), 'rating_y'] = 0\n",
    "user_top_games_filtered_hours_0.rename(columns={'rating_y': 'rating'}, inplace=True)\n",
    "user_top_games_filtered_hours_0.drop(columns='rating_x',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_2 = user_top_games_filtered_hours_0.loc[user_top_games_filtered_hours_0.index.isin(train_val_1.index)]\n",
    "test_2 = user_top_games_filtered_hours_0.loc[user_top_games_filtered_hours_0.index.isin(test_1.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_all_2 = create_interaction_matrix(df = train_val_2,\n",
    "                                                     user_col = 'user',\n",
    "                                                     item_col = 'item',\n",
    "                                                     rating_col = 'rating',\n",
    "                                                     threshold = '1')\n",
    "sparse_train_2 = sparse.csr_matrix(interactions_train_all_2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_test_2 = create_interaction_matrix(df = test_2,\n",
    "                                         user_col = 'user',\n",
    "                                         item_col = 'item',\n",
    "                                         rating_col = 'rating',\n",
    "                                         threshold = '1')\n",
    "sparse_test_2 = sparse.csr_matrix(interactions_test_2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f7dc0e7c2e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = LightFM(**best_parameters)\n",
    "model_2.fit(sparse_train_2,\n",
    "            epochs=15,\n",
    "            num_threads=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_top_games_filtered_hours = user_top_games.merge(user_top_games_filtered_hours, how='left', on=['user','item'])\n",
    "user_top_games_filtered_hours.loc[user_top_games_filtered_hours['rating_y'].isnull(), 'rating_y'] = 0\n",
    "user_top_games_filtered_hours.rename(columns={'rating_y': 'rating'}, inplace=True)\n",
    "user_top_games_filtered_hours.drop(columns='rating_x',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_3 = user_top_games_filtered_hours.loc[user_top_games_filtered_hours.index.isin(train_val_1.index)]\n",
    "test_3 = user_top_games_filtered_hours.loc[user_top_games_filtered_hours.index.isin(test_1.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_all_3 = create_interaction_matrix(df = train_val_3,\n",
    "                                                     user_col = 'user',\n",
    "                                                     item_col = 'item',\n",
    "                                                     rating_col = 'rating',\n",
    "                                                     threshold = '1')\n",
    "sparse_train_3 = sparse.csr_matrix(interactions_train_all_3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_test_3 = create_interaction_matrix(df = test_3,\n",
    "                                         user_col = 'user',\n",
    "                                         item_col = 'item',\n",
    "                                         rating_col = 'rating',\n",
    "                                         threshold = '1')\n",
    "sparse_test_3 = sparse.csr_matrix(interactions_test_3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f7dc133a4a8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = LightFM(**best_parameters)\n",
    "model_3.fit(sparse_train_3,\n",
    "            epochs=15,\n",
    "            num_threads=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_top_games_filtered_percentile = user_top_games.merge(user_top_games_filtered_percentile, how='left', on=['user','item'])\n",
    "user_top_games_filtered_percentile.loc[user_top_games_filtered_percentile['rating_y'].isnull(), 'rating_y'] = 0\n",
    "user_top_games_filtered_percentile.rename(columns={'rating_y': 'rating'}, inplace=True)\n",
    "user_top_games_filtered_percentile.drop(columns='rating_x',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_4 = user_top_games_filtered_percentile.loc[user_top_games_filtered_percentile.index.isin(train_val_1.index)]\n",
    "test_4 = user_top_games_filtered_percentile.loc[user_top_games_filtered_percentile.index.isin(test_1.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_all_4 = create_interaction_matrix(df = train_val_4,\n",
    "                                                     user_col = 'user',\n",
    "                                                     item_col = 'item',\n",
    "                                                     rating_col = 'rating',\n",
    "                                                     threshold = '1')\n",
    "sparse_train_4 = sparse.csr_matrix(interactions_train_all_4.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_test_4 = create_interaction_matrix(df = test_4,\n",
    "                                         user_col = 'user',\n",
    "                                         item_col = 'item',\n",
    "                                         rating_col = 'rating',\n",
    "                                         threshold = '1')\n",
    "sparse_test_4 = sparse.csr_matrix(interactions_test_4.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f7dce85b550>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = LightFM(**best_parameters)\n",
    "model_4.fit(sparse_train_4,\n",
    "            epochs=15,\n",
    "            num_threads=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance on each other's interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_1_1 = auc_score(model_1, sparse_test_1, sparse_train_1, num_threads=30).mean()\n",
    "auc_1_2 = auc_score(model_1, sparse_test_2, sparse_train_2, num_threads=30).mean()\n",
    "auc_1_3 = auc_score(model_1, sparse_test_3, sparse_train_3, num_threads=30).mean()\n",
    "auc_1_4 = auc_score(model_1, sparse_test_4, sparse_train_4, num_threads=30).mean()\n",
    "\n",
    "auc_2_1 = auc_score(model_2, sparse_test_1, sparse_train_1, num_threads=30).mean()\n",
    "auc_2_2 = auc_score(model_2, sparse_test_2, sparse_train_2, num_threads=30).mean()\n",
    "auc_2_3 = auc_score(model_2, sparse_test_3, sparse_train_3, num_threads=30).mean()\n",
    "auc_2_4 = auc_score(model_2, sparse_test_4, sparse_train_4, num_threads=30).mean()\n",
    "\n",
    "auc_3_1 = auc_score(model_3, sparse_test_1, sparse_train_1, num_threads=30).mean()\n",
    "auc_3_2 = auc_score(model_3, sparse_test_2, sparse_train_2, num_threads=30).mean()\n",
    "auc_3_3 = auc_score(model_3, sparse_test_3, sparse_train_3, num_threads=30).mean()\n",
    "auc_3_4 = auc_score(model_3, sparse_test_4, sparse_train_4, num_threads=30).mean()\n",
    "\n",
    "auc_4_1 = auc_score(model_4, sparse_test_1, sparse_train_1, num_threads=30).mean()\n",
    "auc_4_2 = auc_score(model_4, sparse_test_2, sparse_train_2, num_threads=30).mean()\n",
    "auc_4_3 = auc_score(model_4, sparse_test_3, sparse_train_3, num_threads=30).mean()\n",
    "auc_4_4 = auc_score(model_4, sparse_test_4, sparse_train_4, num_threads=30).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 embeddings vs model 1 interactions auc: 0.914515\n",
      "model 1 embeddings vs model 2 interactions auc: 0.9073612\n",
      "model 1 embeddings vs model 3 interactions auc: 0.91035223\n",
      "model 1 embeddings vs model 4 interactions auc: 0.9058233\n",
      "\n",
      "model 2 embeddings vs model 1 interactions auc: 0.8811896\n",
      "model 2 embeddings vs model 2 interactions auc: 0.9106597\n",
      "model 2 embeddings vs model 3 interactions auc: 0.9187266\n",
      "model 2 embeddings vs model 4 interactions auc: 0.90898114\n",
      "\n",
      "model 3 embeddings vs model 1 interactions auc: 0.8624471\n",
      "model 3 embeddings vs model 2 interactions auc: 0.9014988\n",
      "model 3 embeddings vs model 3 interactions auc: 0.91681266\n",
      "model 3 embeddings vs model 4 interactions auc: 0.89959764\n",
      "\n",
      "model 4 embeddings vs model 1 interactions auc: 0.8806335\n",
      "model 4 embeddings vs model 2 interactions auc: 0.9099839\n",
      "model 4 embeddings vs model 3 interactions auc: 0.9180439\n",
      "model 4 embeddings vs model 4 interactions auc: 0.9084542\n"
     ]
    }
   ],
   "source": [
    "print('model 1 embeddings vs model 1 interactions auc: '+str(auc_1_1))\n",
    "print('model 1 embeddings vs model 2 interactions auc: '+str(auc_1_2))\n",
    "print('model 1 embeddings vs model 3 interactions auc: '+str(auc_1_3))\n",
    "print('model 1 embeddings vs model 4 interactions auc: '+str(auc_1_4)+'\\n')\n",
    "\n",
    "print('model 2 embeddings vs model 1 interactions auc: '+str(auc_2_1))\n",
    "print('model 2 embeddings vs model 2 interactions auc: '+str(auc_2_2))\n",
    "print('model 2 embeddings vs model 3 interactions auc: '+str(auc_2_3))\n",
    "print('model 2 embeddings vs model 4 interactions auc: '+str(auc_2_4)+'\\n')\n",
    "\n",
    "print('model 3 embeddings vs model 1 interactions auc: '+str(auc_3_1))\n",
    "print('model 3 embeddings vs model 2 interactions auc: '+str(auc_3_2))\n",
    "print('model 3 embeddings vs model 3 interactions auc: '+str(auc_3_3))\n",
    "print('model 3 embeddings vs model 4 interactions auc: '+str(auc_3_4)+'\\n')\n",
    "\n",
    "print('model 4 embeddings vs model 1 interactions auc: '+str(auc_4_1))\n",
    "print('model 4 embeddings vs model 2 interactions auc: '+str(auc_4_2))\n",
    "print('model 4 embeddings vs model 3 interactions auc: '+str(auc_4_3))\n",
    "print('model 4 embeddings vs model 4 interactions auc: '+str(auc_4_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_2 = 1-train_val_2['rating'].sum()/train_val_1['rating'].sum()\n",
    "ratio_3 = 1-train_val_3['rating'].sum()/train_val_1['rating'].sum()\n",
    "ratio_4 = 1-train_val_4['rating'].sum()/train_val_1['rating'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_r, test_r = train_test_split(user_top_games, test_size=0.2, random_state=1337)\n",
    "#train_r, val_r = train_test_split(train_val_r, test_size=ratio_2, random_state=1337)\n",
    "#train_r, val_r = train_test_split(train_val_r, test_size=ratio_3, random_state=1337)\n",
    "train_r, val_r = train_test_split(train_val_r, test_size=ratio_4, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_r = create_interaction_matrix(df = train_r,\n",
    "                                                 user_col = 'user',\n",
    "                                                 item_col = 'item',\n",
    "                                                 rating_col = 'rating',\n",
    "                                                 threshold = '1')\n",
    "sparse_train_r = sparse.csr_matrix(interactions_train_r.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_test_r = create_interaction_matrix(df = test_r,\n",
    "                                         user_col = 'user',\n",
    "                                         item_col = 'item',\n",
    "                                         rating_col = 'rating',\n",
    "                                         threshold = '1')\n",
    "sparse_test_r = sparse.csr_matrix(interactions_test_r.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlalchemy_conn = create_sqlalchemy_connection('sqlalchemy_conn_str.txt')\n",
    "best_parameters = query_best_parameters('sqlalchemy_conn_str.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f7dc133acf8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r = LightFM(**best_parameters)\n",
    "model_r.fit(sparse_train_r,\n",
    "            epochs=15,\n",
    "            num_threads=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_r_1 = auc_score(model_r, sparse_test_1, sparse_train_1, num_threads=30).mean()\n",
    "auc_r_2 = auc_score(model_r, sparse_test_2, sparse_train_2, num_threads=30).mean()\n",
    "auc_r_3 = auc_score(model_r, sparse_test_3, sparse_train_3, num_threads=30).mean()\n",
    "auc_r_4 = auc_score(model_r, sparse_test_4, sparse_train_4, num_threads=30).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model r embeddings vs model 1 interactions auc: 0.9024247\n",
      "model r embeddings vs model 2 interactions auc: 0.8963152\n",
      "model r embeddings vs model 3 interactions auc: 0.8998613\n",
      "model r embeddings vs model 4 interactions auc: 0.8946328\n"
     ]
    }
   ],
   "source": [
    "print('model r embeddings vs model 1 interactions auc: '+str(auc_r_1))\n",
    "print('model r embeddings vs model 2 interactions auc: '+str(auc_r_2))\n",
    "print('model r embeddings vs model 3 interactions auc: '+str(auc_r_3))\n",
    "print('model r embeddings vs model 4 interactions auc: '+str(auc_r_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2982303411265329\n",
      "0.4067730061125876\n",
      "0.31137760323086094\n"
     ]
    }
   ],
   "source": [
    "print(ratio_2)\n",
    "print(ratio_3)\n",
    "print(ratio_4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
