{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import operator\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "from IPython.display import display as dp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import lightfm as LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import reciprocal_rank\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import lightfm as lfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../lib/cookbook/\"))\n",
    "from recsys import * ## recommender system cookbook\n",
    "from generic_preprocessing import * ## pre-processing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aussie_items = json.load(open('../data/fixed/australian_users_items_fixed.json','r'))\n",
    "steam_games = json.load(open('../data/fixed/steam_games_fixed.json','r'))\n",
    "steam_games_df = pd.read_json('../data/fixed/steam_games_fixed.json', orient='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing utilities: user-item datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_list(user_item_data, _id=False):\n",
    "    user_item = []\n",
    "    for user in user_item_data:\n",
    "        for item in user['items']:\n",
    "            if _id == True:\n",
    "                user_item.append((user['user_id'], item['item_id']))\n",
    "            else:\n",
    "                user_item.append((user['user_id'], item['item_name']))\n",
    "    return user_item\n",
    "\n",
    "\n",
    "def build_df(user_item):\n",
    "    df = pd.DataFrame(user_item, columns=['user', 'item'])\n",
    "    df = df.drop_duplicates(['user', 'item'])\n",
    "    #print(df.shape)\n",
    "    df['own'] = 1\n",
    "    df = df.pivot(index='user', columns='item', values='own')\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_users(user_item_data, _id=False):\n",
    "    user_feat = []\n",
    "    for user in user_item_data:\n",
    "        for item in user['items']:\n",
    "            if _id == True:\n",
    "                user_feat.append(\n",
    "                    (user['user_id'], user['items_count'], item['item_id'],\n",
    "                     item['playtime_forever'], item['playtime_2weeks']))\n",
    "            else:\n",
    "                user_feat.append(\n",
    "                    (user['user_id'], user['items_count'], item['item_name'],\n",
    "                     item['playtime_forever'], item['playtime_2weeks']))\n",
    "    return user_feat\n",
    "\n",
    "\n",
    "def build_users_df(user_feat):\n",
    "    col = [\n",
    "        'user', 'items_count', 'item', 'playtime_forever', 'playtime_2weeks'\n",
    "    ]\n",
    "    feat = pd.DataFrame(user_feat, columns=col)\n",
    "    feat = feat.drop_duplicates(col)\n",
    "    feat['item'] = feat['item'].astype(str, copy=True)\n",
    "    feat['playhour'] = (feat['playtime_forever'].values / 60\n",
    "                        )  # convert min to hour and round up\n",
    "    feat['playhour'] = feat['playhour'].astype(int, copy=True)\n",
    "    feat['playtime'] = (\n",
    "        feat['playhour'].values / 10)  # reduce playtime variance range\n",
    "    feat['playtime'] = feat['playtime'].astype(int, copy=True)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing utilities: game datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------\n",
    "# utilities - check number is NaN\n",
    "#------------------------------------\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "# utilities - round up to nearest 10th\n",
    "#------------------------------------\n",
    "def roundup(x):\n",
    "    return int(math.ceil(x / 10.0)) * 10\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "# genres\n",
    "#------------------------------------\n",
    "def cleanup_genre(genres):\n",
    "    if isNaN(genres) == True:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return genres[0]\n",
    "\n",
    "\n",
    "def generate_genre_mapping(genres):\n",
    "    length = len(genres)\n",
    "    l_val = range(1, length + 1)\n",
    "    return dict(zip(genres, l_val))\n",
    "\n",
    "\n",
    "def cleanup_genre_mapping(genre):\n",
    "    return game_genre_map.get(genre, 0)\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "# release_date\n",
    "#------------------------------------\n",
    "def cleanup_year(dates):\n",
    "    now = datetime.datetime.now()\n",
    "    if isNaN(dates) == True:\n",
    "        return 0\n",
    "    else:\n",
    "        _dates = dates.split('-')\n",
    "        _year = _dates[0]\n",
    "        try:\n",
    "            _year = int(_year)\n",
    "        except ValueError:\n",
    "            _year = int(now.year)\n",
    "        return (now.year - _year)\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "# metascore: this data is too sparse\n",
    "#------------------------------------\n",
    "def cleanup_metascore(score):\n",
    "    if score == 'NA':\n",
    "        return 0\n",
    "    elif isNaN(score) == True:\n",
    "        return 0\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "# price\n",
    "#------------------------------------\n",
    "def cleanup_price(price):\n",
    "    if isinstance(price, str):\n",
    "        if price.find(\"Free\") > 0 or price.find(\"Demo\") > 0:\n",
    "            return 0\n",
    "    elif isNaN(price) == True:\n",
    "        return 0\n",
    "    else:\n",
    "        return round(price)\n",
    "\n",
    "\n",
    "#------------------------------------\n",
    "# clean up and build game datasets\n",
    "#------------------------------------\n",
    "def build_games_df(df, _id=True, _price=False, _date=False, _metascore=False):\n",
    "    if _id == True:\n",
    "        game_feat = df.reindex(\n",
    "            columns=['id', 'genres', 'price', 'release_date', 'metascore'])\n",
    "        game_feat.rename(columns={'id': 'item'}, inplace=True)\n",
    "        game_feat['item'].fillna(0, inplace=True)\n",
    "        game_feat['item'] = game_feat['item'].astype(int, copy=True)\n",
    "        game_feat['item'] = game_feat['item'].astype(str, copy=True)\n",
    "    else:\n",
    "        game_feat = df.reindex(columns=[\n",
    "            'app_name', 'genres', 'price', 'release_date', 'metascore'\n",
    "        ])\n",
    "        game_feat.rename(columns={'app_name': 'item'}, inplace=True)\n",
    "\n",
    "    # metascore\n",
    "    if _metascore == True:\n",
    "        game_feat['metascore'] = game_feat['metascore'].apply(\n",
    "            cleanup_metascore)\n",
    "    else:\n",
    "        game_feat.drop(['metascore'], axis=1, inplace=True)\n",
    "\n",
    "    # price\n",
    "    if _price == True:\n",
    "        game_feat['price'] = game_feat['price'].apply(cleanup_price)\n",
    "        game_feat['price'].fillna(0, inplace=True)\n",
    "        game_feat['price'] = game_feat['price'].astype(int, copy=True)\n",
    "    else:\n",
    "        game_feat.drop(['price'], axis=1, inplace=True)\n",
    "\n",
    "    # release date\n",
    "    if _date == True:\n",
    "        game_feat['age'] = game_feat['release_date'].apply(cleanup_year)\n",
    "        game_feat['year'] = game_feat['release_date'].apply(cleanup_year)\n",
    "    game_feat.drop(['release_date'], axis=1, inplace=True)\n",
    "\n",
    "    game_feat.dropna(inplace=True)\n",
    "\n",
    "    return game_feat\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# calcurate median playtime of users for each game\n",
    "#----------------------------------------------------------\n",
    "def calculate_median_playtime(userdata, itemdata, _drop=True):\n",
    "    playtime_forever = userdata[['item', 'playtime_forever']]\n",
    "    playtime_2weeks = userdata[['item', 'playtime_2weeks']]\n",
    "\n",
    "    median_playtime_forever = playtime_forever.groupby(['item']).median()\n",
    "    median_playtime_2weeks = playtime_2weeks.groupby(['item']).median()\n",
    "    new_df = pd.merge(\n",
    "        median_playtime_forever, median_playtime_2weeks, on=['item'])\n",
    "    new_df = pd.merge(itemdata, new_df, on=['item'])\n",
    "    new_df['playhour_forever'] = round(new_df['playtime_forever'] / 60)\n",
    "    new_df['playhour_2weeks'] = round(new_df['playtime_2weeks'] / 60)\n",
    "\n",
    "    if _drop == True:\n",
    "        new_df.drop(['playtime_forever'], axis=1, inplace=True)\n",
    "        new_df.drop(['playtime_2weeks'], axis=1, inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data filtering utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# Filter by most owned games\n",
    "#----------------------------------------------------------\n",
    "def filter_top_n(user_item_df, n=500):\n",
    "    top_n = user_item_df.sum().nlargest(n).index\n",
    "    user_top_ngames = user_item_df[top_n].stack().reset_index()\n",
    "    user_top_ngames = user_top_ngames.rename(columns={0: 'rating'})\n",
    "    return user_top_ngames\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# return the list of games of given datasets\n",
    "#----------------------------------------------------------\n",
    "def list_games(user_item_df):\n",
    "    games = pd.DataFrame()\n",
    "    games['item'] = user_item_df.item.drop_duplicates()\n",
    "    return games\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# return common game items list between two dataframes\n",
    "#----------------------------------------------------------\n",
    "def filter_common_games(df1, df2):\n",
    "    list1 = sorted(df1.columns, reverse=False)\n",
    "    list2 = sorted(df2['item'].values, reverse=False)\n",
    "    common_item = sorted(list(set(list1).intersection(list2)), reverse=False)\n",
    "    print('common item size:', len(common_item))\n",
    "    df1_f = df1[common_item]\n",
    "    df2_f = df2[df2['item'].isin(common_item)]\n",
    "    return df1_f, df2_f\n",
    "\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# filter top_list of items from dataframe and return\n",
    "#----------------------------------------------------------\n",
    "def filter_top_n_items(df, top_list):\n",
    "    top_df = df[df['item'].isin(top_list)]\n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user-item preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = build_list(aussie_items, _id=True)\n",
    "user_item_df = build_df(user_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user-item preprocessing for user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_users = build_users(aussie_items, _id=True)\n",
    "steam_users_df = build_users_df(steam_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## game preprocessing for item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_items_df = build_games_df(\n",
    "    steam_games_df, _id=True, _price=True, _date=True, _metascore=False)\n",
    "steam_items_all_df = calculate_median_playtime(steam_users_df, steam_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter common top N game items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# Filter common game items between user-item and game datasets\n",
    "#----------------------------------------------------------\n",
    "user_item_df, steam_items_all_df = filter_common_games(user_item_df,\n",
    "                                                       steam_items_all_df)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Filter top N games from user-item\n",
    "# For current modeling,\n",
    "# we are going to run our model with top 1000 games\n",
    "#----------------------------------------------------------\n",
    "n_games = 1000\n",
    "user_top_games = filter_top_n(user_item_df, n_games)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Compose a list of top N games\n",
    "#----------------------------------------------------------\n",
    "games = list_games(user_top_games)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Filter top N items again\n",
    "#----------------------------------------------------------\n",
    "top_items = filter_top_n_items(steam_items_all_df, games['item'].values)\n",
    "top_users = filter_top_n_items(steam_users_df, games['item'].values)\n",
    "\n",
    "# list of data validation\n",
    "print(top_items.shape, top_users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create train and test interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(\n",
    "    user_top_games, test_size=0.2, random_state=1337)\n",
    "\n",
    "interactions_train_all = create_interaction_matrix(\n",
    "    df=train_val,\n",
    "    user_col='user',\n",
    "    item_col='item',\n",
    "    rating_col='rating',\n",
    "    threshold='1')\n",
    "\n",
    "interactions_test = create_interaction_matrix(\n",
    "    df=test,\n",
    "    user_col='user',\n",
    "    item_col='item',\n",
    "    rating_col='rating',\n",
    "    threshold='1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create data dictionaries for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = create_user_dict(interactions=interactions_train_all)\n",
    "user_dict_test = create_user_dict(interactions=interactions_test)\n",
    "games_dict = create_item_dict(df=games, id_col='item', name_col='item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create sparse matrices from interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_all = sparse.csr_matrix(interactions_train_all.values)\n",
    "sparse_test = sparse.csr_matrix(interactions_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape validation\n",
    "print('user_top_games:', user_top_games.shape)\n",
    "print('train_val:', train_val.shape)\n",
    "print('test:', test.shape)\n",
    "print('interactions_train_all:', interactions_train_all.shape)\n",
    "print('interactions_test:', interactions_test.shape)\n",
    "print('sparse_train_all:', sparse_train_all.shape)\n",
    "print('sparse_test:', sparse_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# create item list\n",
    "#----------------------------------------------------------\n",
    "def create_item_list(\n",
    "    dataset_df, \n",
    "    _genres=True, \n",
    "    _playhour_forever=False, \n",
    "    _playhour_2weeks=False, \n",
    "    _price=False, \n",
    "    _age=False):\n",
    "    \n",
    "    s = []\n",
    "    if _genres==True:\n",
    "        for i, x in dataset_df.iterrows():\n",
    "            for i in x.genres:\n",
    "                if i not in s:\n",
    "                    s.append(i)\n",
    "\n",
    "    if _playhour_forever==True:\n",
    "        s.append('playhour_forever')\n",
    "    if _playhour_2weeks==True:\n",
    "        s.append('playhour_2weeks')\n",
    "    if _price==True:\n",
    "        s.append('price')\n",
    "    if _age==True:\n",
    "        s.append('age')\n",
    "\n",
    "    return s\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create item feature\n",
    "#----------------------------------------------------------\n",
    "def create_item_feature(\n",
    "    item_df, \n",
    "    _genres=True, \n",
    "    _playhour_forever=False, \n",
    "    _playhour_2weeks=False, \n",
    "    _price=False, \n",
    "    _age=False):\n",
    "    z = 0\n",
    "    diclist = []\n",
    "    \n",
    "    for i, x in item_df.iterrows():\n",
    "        klist = []\n",
    "        if _genres==True:\n",
    "            for genre in x.genres:\n",
    "                klist.append(genre)\n",
    "        if _playhour_forever==True:\n",
    "            klist.append('playhour_forever')\n",
    "        if _playhour_2weeks==True:\n",
    "            klist.append('playhour_2weeks')\n",
    "        if _price==True:\n",
    "            klist.append('price')\n",
    "        if _age==True:\n",
    "            klist.append('age')\n",
    "        \n",
    "        vlist = []\n",
    "        if _genres==True:\n",
    "            for i in range(len(x.genres)):\n",
    "                vlist.append(1) \n",
    "        if _playhour_forever==True:\n",
    "            vlist.append(x.playhour_forever)\n",
    "        if _playhour_2weeks==True:\n",
    "            vlist.append(x.playhour_2weeks)\n",
    "        if _price==True:\n",
    "            vlist.append(x.price)\n",
    "        if _age==True:\n",
    "            vlist.append(x.age)\n",
    "            \n",
    "        diclist.append((x['item'], dict(zip(klist, vlist))))\n",
    "\n",
    "    df = pd.DataFrame({'features':diclist})\n",
    "    return df, diclist\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# normalize item feature values\n",
    "#----------------------------------------------------------\n",
    "def normalize_item_values(\n",
    "    dataset_df, \n",
    "    _playhour_forever=False, \n",
    "    _playhour_2weeks=False, \n",
    "    _price=False, \n",
    "    _age=False):\n",
    "    \n",
    "    s = []\n",
    "    if _playhour_forever==True:\n",
    "        s.append('playhour_forever')\n",
    "    if _playhour_2weeks==True:\n",
    "        s.append('playhour_2weeks')\n",
    "    if _price==True:\n",
    "        s.append('price')\n",
    "    if _age==True:\n",
    "        s.append('age')\n",
    "\n",
    "    dataset = dataset_df[s]\n",
    "    x = preprocessing.normalize(dataset.values, norm='l1')\n",
    "    return x\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# convert a value to a binary type\n",
    "#----------------------------------------------------------\n",
    "def convert2binary(df):\n",
    "    for column in df:\n",
    "        df[column] = (df[column] > 0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_feat, train_data, test_data, item_feat=None, user_feat=None):\n",
    "    train_auc = auc_score(model_feat, \n",
    "                          train_data, \n",
    "                          item_features=item_feat,\n",
    "                          user_features=user_feat).mean()\n",
    "    print('AUC: train %.3f.' % (train_auc))\n",
    "\n",
    "    test_auc = auc_score(model_feat, \n",
    "                         test_data, \n",
    "                         train_data,\n",
    "                         item_features=item_feat,\n",
    "                         user_features=item_feat).mean()\n",
    "    print('AUC: test %.3f.' % (test_auc))\n",
    "    return train_auc, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collaborative filtering - bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bpr = LightFM(\n",
    "    no_components=30,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='bpr',\n",
    "    learning_rate=0.05,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-05,\n",
    "    item_alpha=0.001,\n",
    "    user_alpha=0.001,\n",
    "    random_state=1337)\n",
    "start_time = time.time()\n",
    "model_bpr.fit(sparse_train_all, epochs=15, num_threads=8)\n",
    "end_time = time.time()\n",
    "print('Time taken for model train: {}'.format(str(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(model_bpr, sparse_train_all, sparse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collaborative filtering - warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_warp = LightFM(\n",
    "    no_components=50,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='warp',\n",
    "    learning_rate=0.05,\n",
    "    k=5,\n",
    "    n=10,\n",
    "    rho=0.82,\n",
    "    epsilon=1e-06,\n",
    "    item_alpha=0.0005,\n",
    "    user_alpha=0.0001,\n",
    "    max_sampled=10,\n",
    "    random_state=1337)\n",
    "start_time = time.time()\n",
    "model_warp.fit(sparse_train_all, epochs=15, num_threads=8)\n",
    "end_time = time.time()\n",
    "print('Time taken for model train: {}'.format(str(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(model_warp, sparse_train_all, sparse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Hybrid (collaborative filtering + content-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid model 1\n",
    "  - loss function: bpr\n",
    "  - item features: genres, playhour_forever, playhour_2weeks, price, release_date\n",
    "  - user features: none\n",
    "  - feature normalization: lightfm library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# generate item list\n",
    "#----------------------------------------------------------\n",
    "top_items = top_items.reset_index(drop=True)\n",
    "item_feature_list = create_item_list(\n",
    "    top_items,\n",
    "    _genres=True,\n",
    "    _playhour_forever=True,\n",
    "    _playhour_2weeks=True,\n",
    "    _price=True,\n",
    "    _age=True)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create dataset\n",
    "#----------------------------------------------------------\n",
    "dataset = Dataset(user_identity_features=True, item_identity_features=True)\n",
    "dataset.fit(\n",
    "    users=set(user_top_games['user'].values),\n",
    "    items=set(top_items['item'].values),\n",
    "    user_features=None,  #user_features_list,\n",
    "    item_features=item_feature_list)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# item features generation\n",
    "#----------------------------------------------------------\n",
    "item_feature, item_diclist = create_item_feature(\n",
    "    top_items,\n",
    "    _genres=True,\n",
    "    _playhour_forever=True,\n",
    "    _playhour_2weeks=True,\n",
    "    _price=True,\n",
    "    _age=True)\n",
    "lfm_item_features = dataset.build_item_features(\n",
    "    item_feature['features'].values)\n",
    "\n",
    "lfm_item_features_df = pd.DataFrame(lfm_item_features.todense())\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create sum by each row\n",
    "#----------------------------------------------------------\n",
    "lfm_features_all_m = lfm_item_features_df.values\n",
    "lfm_features_m = (lfm_features_all_m) / lfm_features_all_m.sum(\n",
    "    axis=1, keepdims=1)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create sparse matrix\n",
    "#----------------------------------------------------------\n",
    "sparse_features_all = sparse.csr_matrix(lfm_item_features_df.values)\n",
    "sparse_features_all_m = sparse.csr_matrix(lfm_features_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid_bpr = LightFM(\n",
    "    no_components=30,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='bpr',\n",
    "    learning_rate=0.05,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-05,\n",
    "    item_alpha=0.001,\n",
    "    user_alpha=0.001,\n",
    "    random_state=1337)\n",
    "start_time = time.time()\n",
    "model_hybrid_bpr.fit(\n",
    "    sparse_train_all,\n",
    "    item_features=sparse_features_all_m,\n",
    "    user_features=None,\n",
    "    epochs=15,\n",
    "    num_threads=8)\n",
    "end_time = time.time()\n",
    "print('Time taken for model train: {}'.format(str(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(\n",
    "    model_hybrid_bpr,\n",
    "    sparse_train_all,\n",
    "    sparse_test,\n",
    "    item_feat=sparse_features_all_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid model 2\n",
    "  - loss function: warp\n",
    "  - item features: genres, playhour_forever, playhour_2weeks, price, release_date\n",
    "  - user features: none\n",
    "  - feature normalization: lightfm library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid_warp = LightFM(\n",
    "    no_components=50,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='warp',\n",
    "    learning_rate=0.05,\n",
    "    k=5,\n",
    "    n=10,\n",
    "    rho=0.82,\n",
    "    epsilon=1e-06,\n",
    "    item_alpha=0.0005,\n",
    "    user_alpha=0.0001,\n",
    "    max_sampled=10,\n",
    "    random_state=1337)\n",
    "start_time = time.time()\n",
    "model_hybrid_warp.fit(\n",
    "    sparse_train_all,\n",
    "    item_features=sparse_features_all_m,\n",
    "    user_features=None,\n",
    "    epochs=15,\n",
    "    num_threads=8)\n",
    "end_time = time.time()\n",
    "print('Time taken for model train: {}'.format(str(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(\n",
    "    model_hybrid_warp,\n",
    "    sparse_train_all,\n",
    "    sparse_test,\n",
    "    item_feat=sparse_features_all_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid model 3\n",
    "  - loss function: bpr\n",
    "  - item features: genres \n",
    "  - user features: none\n",
    "  - feature normalization: sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# generate item list\n",
    "#----------------------------------------------------------\n",
    "top_items = top_items.reset_index(drop=True)\n",
    "item_feature_list = create_item_list(\n",
    "    top_items,\n",
    "    _genres=True,\n",
    "    _playhour_forever=False,\n",
    "    _playhour_2weeks=False,\n",
    "    _price=False,\n",
    "    _age=False)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create dataset\n",
    "#----------------------------------------------------------\n",
    "dataset = Dataset(user_identity_features=True, item_identity_features=True)\n",
    "dataset.fit(\n",
    "    users=set(user_top_games['user'].values),\n",
    "    items=set(top_items['item'].values),\n",
    "    user_features=None,  #user_features_list,\n",
    "    item_features=item_feature_list)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# item features generation\n",
    "#----------------------------------------------------------\n",
    "item_feature, item_diclist = create_item_feature(\n",
    "    top_items,\n",
    "    _genres=True,\n",
    "    _playhour_forever=False,\n",
    "    _playhour_2weeks=False,\n",
    "    _price=False,\n",
    "    _age=False)\n",
    "\n",
    "lfm_item_features = dataset.build_item_features(\n",
    "    item_feature['features'].values)\n",
    "\n",
    "lfm_item_features_df = pd.DataFrame(lfm_item_features.todense())\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create sum by each row\n",
    "#----------------------------------------------------------\n",
    "lfm_features_all_m = lfm_item_features_df.values\n",
    "lfm_features_m = preprocessing.normalize(lfm_features_all_m, norm='l1', axis=1)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create sparse matrix\n",
    "#----------------------------------------------------------\n",
    "sparse_features_all = sparse.csr_matrix(lfm_item_features_df.values)\n",
    "sparse_features_all_m = sparse.csr_matrix(lfm_features_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid_bpr = LightFM(\n",
    "    no_components=30,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='bpr',\n",
    "    learning_rate=0.05,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-05,\n",
    "    item_alpha=0.001,\n",
    "    user_alpha=0.001,\n",
    "    random_state=1337)\n",
    "start_time = time.time()\n",
    "model_hybrid_bpr.fit(\n",
    "    sparse_train_all,\n",
    "    item_features=sparse_features_all_m,\n",
    "    user_features=None,\n",
    "    epochs=15,\n",
    "    num_threads=8)\n",
    "end_time = time.time()\n",
    "print('Time taken for model train: {}'.format(str(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(\n",
    "    model_hybrid_bpr,\n",
    "    sparse_train_all,\n",
    "    sparse_test,\n",
    "    item_feat=sparse_features_all_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid model 4\n",
    "  - loss function: bpr\n",
    "  - item features: genres, playhour_forever, playhour_2weeks, price, release_date\n",
    "  - user features: none\n",
    "  - feature normalization: sklearn library - feature by feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# generate item list\n",
    "#----------------------------------------------------------\n",
    "top_items = top_items.reset_index(drop=True)\n",
    "\n",
    "item_feature_list = create_item_list(\n",
    "    top_items,\n",
    "    _genres=True,\n",
    "    _playhour_forever=True,\n",
    "    _playhour_2weeks=True,\n",
    "    _price=True,\n",
    "    _age=True)\n",
    "\n",
    "item_list1 = create_item_list(\n",
    "    top_items,\n",
    "    _genres=True,\n",
    "    _playhour_forever=False,\n",
    "    _playhour_2weeks=False,\n",
    "    _price=False,\n",
    "    _age=False)\n",
    "\n",
    "item_list2 = create_item_list(\n",
    "    top_items,\n",
    "    _genres=False,\n",
    "    _playhour_forever=True,\n",
    "    _playhour_2weeks=True,\n",
    "    _price=True,\n",
    "    _age=True)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create dataset\n",
    "#----------------------------------------------------------\n",
    "dataset = Dataset(user_identity_features=True, item_identity_features=True)\n",
    "dataset.fit(\n",
    "    users=set(user_top_games['user'].values),\n",
    "    items=set(top_items['item'].values),\n",
    "    user_features=None,\n",
    "    item_features=item_list1)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# item features generation\n",
    "#----------------------------------------------------------\n",
    "item1_feature, item1_diclist = create_item_feature(\n",
    "    top_items,\n",
    "    _genres=True,\n",
    "    _playhour_forever=False,\n",
    "    _playhour_2weeks=False,\n",
    "    _price=False,\n",
    "    _age=False)\n",
    "lfm_item1_features = dataset.build_item_features(\n",
    "    item1_feature['features'].values)\n",
    "\n",
    "lfm_item1_features_df = pd.DataFrame(lfm_item1_features.todense())\n",
    "lfm_item1_features_df = convert2binary(lfm_item1_features_df)\n",
    "\n",
    "item_norm = normalize_item_values(\n",
    "    top_items,\n",
    "    _playhour_forever=True,\n",
    "    _playhour_2weeks=True,\n",
    "    _price=True,\n",
    "    _age=True)\n",
    "lfm_item2_features_df = pd.DataFrame(item_norm)\n",
    "\n",
    "lfm_features_all = pd.concat([lfm_item1_features_df, lfm_item2_features_df],\n",
    "                             axis=1,\n",
    "                             sort=False)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create sum by each row\n",
    "#----------------------------------------------------------\n",
    "lfm_features_all_m = lfm_features_all.values\n",
    "lfm_features_m = (lfm_features_all_m) / lfm_features_all_m.sum(\n",
    "    axis=1, keepdims=1)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# create sparse matrix\n",
    "#----------------------------------------------------------\n",
    "sparse_features_all = sparse.csr_matrix(lfm_features_all.values)\n",
    "sparse_features_all_m = sparse.csr_matrix(lfm_features_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid_bpr = LightFM(\n",
    "    no_components=30,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='bpr',\n",
    "    learning_rate=0.05,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-05,\n",
    "    item_alpha=0.001,\n",
    "    user_alpha=0.001,\n",
    "    random_state=1337)\n",
    "start_time = time.time()\n",
    "model_hybrid_bpr.fit(\n",
    "    sparse_train_all,\n",
    "    item_features=sparse_features_all_m,\n",
    "    user_features=None,\n",
    "    epochs=15,\n",
    "    num_threads=8)\n",
    "end_time = time.time()\n",
    "print('Time taken for model train: {}'.format(str(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(\n",
    "    model_hybrid_bpr,\n",
    "    sparse_train_all,\n",
    "    sparse_test,\n",
    "    item_feat=sparse_features_all_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid model 5\n",
    "  - loss function: warp\n",
    "  - item features: genres, playhour_forever, playhour_2weeks, price, release_date\n",
    "  - user features: none\n",
    "  - feature normalization: sklearn library - feature by feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hybrid_warp = LightFM(\n",
    "    no_components=50,\n",
    "    learning_schedule='adagrad',\n",
    "    loss='warp',\n",
    "    learning_rate=0.05,\n",
    "    k=5,\n",
    "    n=10,\n",
    "    rho=0.82,\n",
    "    epsilon=1e-06,\n",
    "    item_alpha=0.0005,\n",
    "    user_alpha=0.0001,\n",
    "    max_sampled=10,\n",
    "    random_state=1337)\n",
    "start_time = time.time()\n",
    "model_hybrid_warp.fit(\n",
    "    sparse_train_all,\n",
    "    item_features=sparse_features_all_m,\n",
    "    user_features=None,\n",
    "    epochs=15,\n",
    "    num_threads=8)\n",
    "end_time = time.time()\n",
    "print('Time taken for model train: {}'.format(str(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(\n",
    "    model_hybrid_warp,\n",
    "    sparse_train_all,\n",
    "    sparse_test,\n",
    "    item_feat=sparse_features_all_m)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
